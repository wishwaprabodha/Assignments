{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import codecs\n",
    "from nltk import FreqDist\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(dir):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            r.append(os.path.join(root, name))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_f=[]\n",
    "rec_f=[]\n",
    "sci_f=[]\n",
    "talk_f=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list_files('/home/wishwa/COSC/ML/1/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_files(files):\n",
    "    for file in files:\n",
    "        if \"comp\" in file:\n",
    "            comp_f.append(file)\n",
    "        elif \"rec\" in file:\n",
    "            rec_f.append(file)\n",
    "        elif \"sci\" in file:\n",
    "            sci_f.append(file)\n",
    "        elif \"talk\" in file:\n",
    "            talk_f.append(file)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorize_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(file):\n",
    "    lt=[]\n",
    "    wtxt = codecs.open(file,encoding='utf-8', errors='ignore').read()\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    tokenizer = RegexpTokenizer(r'[a-z,A-Z]{2,}')\n",
    "    token=tokenizer.tokenize(wtxt)\n",
    "    for w in token:\n",
    "        w = w.translate(str.maketrans('','',string.punctuation))\n",
    "        if w not in stopWords:\n",
    "            lt.append(w.lower())\n",
    "    return lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in comp_f:\n",
    "    comp=process_files(file)\n",
    "for file in rec_f:\n",
    "    rec=process_files(file)\n",
    "for file in sci_f:\n",
    "    sci=process_files(file)\n",
    "for file in talk_f:\n",
    "    talk=process_files(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "trans = vectorizer.fit_transform(comp)\n",
    "features=vectorizer.get_feature_names()\n",
    "df = pd.DataFrame(trans.toarray(), columns = features)\n",
    "df.to_csv(\"comp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_train,comp_test = train_test_split(comp, train_size=0.7,test_size=0.3, random_state=42)\n",
    "rec_train, rec_test = train_test_split(rec, train_size=0.7,test_size=0.3, random_state=42)\n",
    "sci_train, sci_test = train_test_split(sci, train_size=0.7,test_size=0.3, random_state=42)\n",
    "talk_train,talk_test = train_test_split(talk, train_size=0.7,test_size=0.3, random_state=42)\n",
    "other_train, other_test = train_test_split(other, train_size=0.7,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_d={}\n",
    "for word in comp:\n",
    "    if word not in comp_d:\n",
    "        comp_d[word]=1\n",
    "    else :\n",
    "        comp_d[word]=comp_d[word]+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
