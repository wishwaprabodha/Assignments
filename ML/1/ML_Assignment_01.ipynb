{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import codecs\n",
    "from nltk import FreqDist\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(dir):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            r.append(os.path.join(root, name))\n",
    "    return r\n",
    "files = list_files('/home/wishwa/COSC/ML/1/Data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(file):\n",
    "    wtxt = codecs.open(file,encoding='utf-8', errors='ignore').read()\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    tokenizer = RegexpTokenizer(r'[a-z,A-Z]{2,}')\n",
    "    token=tokenizer.tokenize(wtxt)\n",
    "    lt=[]\n",
    "    for w in token:\n",
    "        w = w.translate(str.maketrans('','',string.punctuation))\n",
    "        if w not in stopWords:\n",
    "            lt.append(w.lower())\n",
    "    print(stopWords)\n",
    "    return lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for file in files:\n",
    "    data=process_files(file)\n",
    "#print(data)    \n",
    "data_train, data_test = train_test_split(data, train_size=0.7,test_size=0.3, random_state=42)\n",
    "len(data_train)/(len(data_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp=[]\n",
    "rec=[]\n",
    "sci=[]\n",
    "talk=[]\n",
    "other=[]\n",
    "for fname in files:\n",
    "    if \"comp\" in fname:\n",
    "        for w in process_files(fname):\n",
    "            if w not in comp:\n",
    "                comp.append(w)\n",
    "    elif \"rec\" in fname:\n",
    "        for w in process_files(fname):\n",
    "            if w not in rec:\n",
    "                rec.append(w)\n",
    "    elif \"sci\" in fname:\n",
    "        for w in process_files(fname):\n",
    "            if w not in sci:\n",
    "                sci.append(w)\n",
    "    elif \"talk\" in fname:\n",
    "        for w in process_files(fname):\n",
    "            if w not in talk:\n",
    "                talk.append(w)\n",
    "    else:\n",
    "        for w in process_files(fname):\n",
    "            if w not in other:\n",
    "                other.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pd.DataFrame(comp)\n",
    "df_comp.to_csv('comp.csv', index=False, header=False)\n",
    "df_rec = pd.DataFrame(rec)\n",
    "df_rec.to_csv('rec.csv', index=False, header=False)\n",
    "df_sci = pd.DataFrame(sci)\n",
    "df_sci.to_csv('sci.csv', index=False, header=False)\n",
    "df_talk = pd.DataFrame(talk)\n",
    "df_talk.to_csv('talk.csv', index=False, header=False)\n",
    "df_other = pd.DataFrame(other)\n",
    "df_other.to_csv('other.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_other(dir):\n",
    "    fPath = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            fPath.append(os.path.join(root, name))\n",
    "    return fPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list_files_other('/home/wishwa/COSC/ML/1/Data')\n",
    "comp_dist = FreqDist()\n",
    "rec_dist = FreqDist()\n",
    "sci_dist = FreqDist()\n",
    "talk_dist = FreqDist()\n",
    "other_dist = FreqDist()\n",
    "stopWords = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'[a-z,A-Z]{2,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_other(file,stopWords,tokenizer):\n",
    "    wtxt = codecs.open(file,encoding='utf-8', errors='ignore').read()\n",
    "    token=tokenizer.tokenize(wtxt)\n",
    "    for word in token:\n",
    "        word = word.translate(str.maketrans('','',string.punctuation))\n",
    "        if word not in stopWords:\n",
    "            if \"comp\" in file:\n",
    "                comp_dist.update([word.lower(),])\n",
    "            elif \"rec\" in file:\n",
    "                rec_dist.update([word.lower(),])\n",
    "            elif \"sci\" in file:\n",
    "                sci_dist.update([word.lower(),])\n",
    "            elif \"talk\" in file:\n",
    "                talk_dist.update([word.lower(),])\n",
    "            else:\n",
    "                other_dist.update([word.lower(),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    process_files_other(file,stopWords,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'edu': 14880, 'com': 8936, 'the': 8650, 'from': 8338, 'subject': 8263, 'lines': 8119, 'organization': 8037, 'in': 7128, 'writes': 6428, 're': 6326, ...})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pd.DataFrame(list(comp_dist.keys()))\n",
    "df_comp.to_csv('compA.csv', index=False, header=False)\n",
    "df_rec = pd.DataFrame(rec)\n",
    "df_rec.to_csv('recA.csv', index=False, header=False)\n",
    "df_sci = pd.DataFrame(sci)\n",
    "df_sci.to_csv('sciA.csv', index=False, header=False)\n",
    "df_talk = pd.DataFrame(talk)\n",
    "df_talk.to_csv('talkA.csv', index=False, header=False)\n",
    "df_other = pd.DataFrame(other)\n",
    "df_other.to_csv('otherA.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
