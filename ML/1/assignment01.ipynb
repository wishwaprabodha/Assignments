{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import codecs\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(dir):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            r.append(os.path.join(root, name))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_f=[]\n",
    "rec_f=[]\n",
    "sci_f=[]\n",
    "talk_f=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list_files('/home/wishwa/COSC/ML/1/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_files(files):\n",
    "    for file in files:\n",
    "        if \"comp\" in file:\n",
    "            comp_f.append(file)\n",
    "        elif \"rec\" in file:\n",
    "            rec_f.append(file)\n",
    "        elif \"sci\" in file:\n",
    "            sci_f.append(file)\n",
    "        elif \"talk\" in file:\n",
    "            talk_f.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize filenames accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorize_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_train,comp_test = train_test_split(comp_f, train_size=0.7,test_size=0.3, random_state=42)\n",
    "rec_train, rec_test = train_test_split(rec_f, train_size=0.7,test_size=0.3, random_state=42)\n",
    "sci_train, sci_test = train_test_split(sci_f, train_size=0.7,test_size=0.3, random_state=42)\n",
    "talk_train,talk_test = train_test_split(talk_f, train_size=0.7,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(file):\n",
    "    lt=[]\n",
    "    wtxt = codecs.open(file,encoding='utf-8', errors='ignore').read()\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    tokenizer = RegexpTokenizer(r'[a-z,A-Z]{2,}')\n",
    "    token=tokenizer.tokenize(wtxt)\n",
    "    for w in token:\n",
    "        w = w.translate(str.maketrans('','',string.punctuation))\n",
    "        if w.lower() not in stopWords and w.lower() not in lt:\n",
    "            lt.append(w)\n",
    "    return lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "compTrain=[]\n",
    "recTrain=[]\n",
    "sciTrain=[]\n",
    "talkTrain=[]\n",
    "compTest=[]\n",
    "recTest=[]\n",
    "sciTest=[]\n",
    "talkTest=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in comp_train:\n",
    "    compTrain.append(process_files(file))\n",
    "for file in rec_train:\n",
    "    recTrain.append(process_files(file))\n",
    "for file in sci_train:\n",
    "    sciTrain.append(process_files(file))\n",
    "for file in talk_train:\n",
    "    talkTrain.append(process_files(file))\n",
    "for file in comp_test:\n",
    "    compTest.append(process_files(file))\n",
    "for file in rec_test:\n",
    "    recTest.append(process_files(file))\n",
    "for file in sci_test:\n",
    "    sciTest.append(process_files(file))\n",
    "for file in talk_test:\n",
    "    talkTest.append(process_files(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Iterable\n",
    "def flatten(list):\n",
    "    for i in list:\n",
    "        for j in i:\n",
    "            yield j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_list(lst):\n",
    "    lt=[]\n",
    "    lt=flatten(lst)\n",
    "    llt=list(lt)\n",
    "    return llt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(dataList):\n",
    "    l=flat_list(dataList)\n",
    "    data=[]\n",
    "    for dt in l:\n",
    "        data.append(dt)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list with categorized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comptrain=convert_to_list(compTrain)\n",
    "rectrain=convert_to_list(recTrain)\n",
    "scitrain=convert_to_list(sciTrain)\n",
    "talktrain=convert_to_list(talkTrain)\n",
    "comptest=convert_to_list(compTest)\n",
    "rectest=convert_to_list(recTest)\n",
    "scitest=convert_to_list(sciTest)\n",
    "talktest=convert_to_list(talkTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def list_to_dic(dataList):\n",
    "    fq= defaultdict( int )\n",
    "    for word in dataList:\n",
    "        fq[word] += 1\n",
    "    return fq  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert list to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_dist_tr = list_to_dic(comptrain)\n",
    "rec_dist_tr= list_to_dic(rectrain)\n",
    "sci_dist_tr= list_to_dic(scitrain)\n",
    "talk_dist_tr= list_to_dic(talktrain)\n",
    "comp_dist_te= list_to_dic(comptest)\n",
    "sci_dist_te= list_to_dic(scitest)\n",
    "talk_dist_te= list_to_dic(talktest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Words to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_train = pd.DataFrame(comptrain)\n",
    "df_comp_test= pd.DataFrame(comptest)\n",
    "df_rec_train = pd.DataFrame(rectrain)\n",
    "df_rec_test = pd.DataFrame(rectest)\n",
    "df_sci_train = pd.DataFrame(scitrain)\n",
    "df_sci_test = pd.DataFrame(scitest)\n",
    "df_talk_train = pd.DataFrame(talktrain)\n",
    "df_talk_test = pd.DataFrame(talktest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_train.to_csv('comptrain.csv', index=False, header=False)\n",
    "df_comp_test.to_csv('comptest.csv', index=False, header=False)\n",
    "df_rec_train.to_csv('rectrain.csv', index=False, header=False)\n",
    "df_rec_test.to_csv('rectest.csv', index=False, header=False)\n",
    "df_sci_train.to_csv('scitrain.csv', index=False, header=False)\n",
    "df_sci_test.to_csv('scitest.csv', index=False, header=False)\n",
    "df_talk_train.to_csv('talktrain.csv', index=False, header=False)\n",
    "df_talk_test.to_csv('talktest.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine list  for categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all=comptrain+rectrain+scitrain+talktrain\n",
    "test_all=comptest+rectest+scitest+talktest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file by file in categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_content(file):\n",
    "    fileContentList=process_files(file)\n",
    "    fileContentDict=list_to_dic(fileContentList)\n",
    "    return fileContentDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing dataframe for sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft=['/home/wishwa/COSC/ML/1/Data/20news-bydate-test/rec.sport.baseball/104819',\n",
    " '/home/wishwa/COSC/ML/1/Data/20news-bydate-test/rec.sport.baseball/104866',\n",
    " '/home/wishwa/COSC/ML/1/Data/20news-bydate-test/rec.sport.baseball/104652',\n",
    " '/home/wishwa/COSC/ML/1/Data/20news-bydate-test/rec.sport.baseball/104686',\n",
    " '/home/wishwa/COSC/ML/1/Data/20news-bydate-test/rec.sport.baseball/104979',\n",
    " '/home/wishwa/COSC/ML/1/Data/20news-bydate-test/rec.sport.baseball/104744',\n",
    " '/home/wishwa/COSC/ML/1/Data/20news-bydate-test/rec.sport.baseball/104680',\n",
    " '/home/wishwa/COSC/ML/1/Data/20news-bydate-test/rec.sport.baseball/104669']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bwolfe</th>\n",
       "      <th>trentu</th>\n",
       "      <th>ca</th>\n",
       "      <th>BEN</th>\n",
       "      <th>WOLFE</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Hardware</th>\n",
       "      <th>Fits</th>\n",
       "      <th>mail</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>know</th>\n",
       "      <th>adequate</th>\n",
       "      <th>fits</th>\n",
       "      <th>acronym</th>\n",
       "      <th>Andrew</th>\n",
       "      <th>Diederich</th>\n",
       "      <th>opinions</th>\n",
       "      <th>mine</th>\n",
       "      <th>alternate</th>\n",
       "      <th>Tuesdays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 1625183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  bwolfe trentu ca BEN WOLFE Subject Hardware Fits mail order   ...    know  \\\n",
       "0      0      0  0   0     0       1        0    0    0     0   ...       0   \n",
       "1      0      0  0   0     0       1        0    0    0     0   ...       0   \n",
       "2      0      0  0   0     0       1        0    0    0     0   ...       0   \n",
       "3      0      0  0   0     0       1        0    0    0     0   ...       0   \n",
       "4      0      0  0   0     0       1        0    0    0     0   ...       0   \n",
       "5      0      0  0   0     0       1        0    0    0     0   ...       0   \n",
       "6      0      0  1   0     0       1        0    0    0     0   ...       0   \n",
       "7      0      0  0   0     0       1        0    0    0     0   ...       0   \n",
       "\n",
       "  adequate fits acronym Andrew Diederich opinions mine alternate Tuesdays  \n",
       "0        0    0       0      0         0        0    0         0        0  \n",
       "1        0    0       0      0         0        0    0         0        0  \n",
       "2        0    0       0      0         0        0    0         0        0  \n",
       "3        0    0       0      0         0        0    0         0        0  \n",
       "4        0    0       0      0         0        0    0         0        0  \n",
       "5        0    0       0      0         0        0    0         0        0  \n",
       "6        0    0       0      0         0        0    0         0        0  \n",
       "7        0    0       0      0         0        0    0         0        0  \n",
       "\n",
       "[8 rows x 1625183 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "ls=train_all\n",
    "dfA = pd.DataFrame(columns=train_all)\n",
    "for f in ft:\n",
    "    lt=[]\n",
    "    dic=read_file_content(f)\n",
    "    diclist=list(dic.keys())\n",
    "    for word in ls:\n",
    "        if word not in diclist:\n",
    "            lt.append(0)\n",
    "        else:\n",
    "            lt.append(dic[word])\n",
    "    dfA.loc[i] = [lt[n] for n in range(len(lt))]\n",
    "    i=i+1\n",
    "dfA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_df(fileCategory,wordList):\n",
    "    i=0\n",
    "    df = pd.DataFrame(columns=wordList)\n",
    "    for f in fileCategory:\n",
    "        lt=[]\n",
    "        dic=read_file_content(f)\n",
    "        diclist=list(dic.keys())\n",
    "        for word in fileCategory:\n",
    "            if word not in diclist:\n",
    "                lt.append(0)\n",
    "            else:\n",
    "                lt.append(dic[word])\n",
    "        df.loc[i] = [lt[n] for n in range(len(lt))]\n",
    "        i=i+1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This part cannot be executed due to insufficient hardware requirements to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcomptrain=add_to_df(comptrain,train_all)\n",
    "dfrectrain=add_to_df(rectrain,train_all)\n",
    "dfscitrain=add_to_df(scitrain,train_all)\n",
    "dftalktrain=add_to_df(talktrain,train_all)\n",
    "dfcomptest=add_to_df(comptest,test_all)\n",
    "dfrectest=add_to_df(rectest,test_all)\n",
    "dfscitest=add_to_df(scitest,test_all)\n",
    "dftalktest=add_to_df(talktest,test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcomptrain.to_csv(\"dfcomptrain.csv\")\n",
    "dfrectrain.to_csv(\"dfrectrain.csv\")\n",
    "dfscitrain.to_csv(\"dfscitrain.csv\")\n",
    "dftalktrain.to_csv(\"dftalktrain.csv\")\n",
    "dfcomptest.to_csv(\"dfcomptest.csv\")\n",
    "dfrectest.to_csv(\"dfrectest.csv\")\n",
    "dfscitest.to_csv(\"dfscitest.csv\")\n",
    "dftalktest.to_csv(\"dftalktest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
